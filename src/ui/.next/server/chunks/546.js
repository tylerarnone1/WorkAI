exports.id=546,exports.ids=[546],exports.modules={56910:(a,b,c)=>{"use strict";let d,e;c.d(b,{VX:()=>W,NF:()=>X,Dj:()=>V});var f=c(81767);class g{constructor(a){this.config=a}}function h(a){return{id:a.id,name:a.function.name,arguments:JSON.parse(a.function.arguments)}}class i extends Error{constructor(a,b,c=500,d){super(a),this.code=b,this.statusCode=c,this.context=d,this.name="AppError"}}class j extends i{constructor(a,b){super(a,"VALIDATION_ERROR",400,b),this.name="ValidationError"}}class k extends i{constructor(a,b,c){super(b,"PROVIDER_ERROR",502,{provider:a,...c}),this.name="ProviderError"}}var l=c(44854),m=c.n(l);function n(a){return(!d&&(d=function(a="info"){return process.env.PINO_PRETTY_DISABLED,d=m()({level:a,transport:void 0})}()),d).child(a)}let o=n({module:"anthropic-provider"});class p extends g{constructor(a){super(a),this.providerType="anthropic",this.client=new f.Ay({apiKey:a.apiKey,...a.baseUrl?{baseURL:a.baseUrl}:{}})}async complete(a){let b=Date.now(),c=a.model??this.config.model;try{let d=this.convertMessages(a.messages),e=a.tools?a.tools.map(a=>({name:a.name,description:a.description,input_schema:{type:"object",properties:a.parameters.properties,required:a.parameters.required}})):void 0,f={model:c,max_tokens:a.maxTokens??4096,messages:d,...a.systemPrompt?{system:a.systemPrompt}:{},...e&&e.length>0?{tools:e}:{},...void 0!==a.temperature?{temperature:a.temperature}:{},...a.stopSequences?{stop_sequences:a.stopSequences}:{}};a.toolChoice&&e&&e.length>0&&("auto"===a.toolChoice?f.tool_choice={type:"auto"}:"none"===a.toolChoice?delete f.tools:"required"===a.toolChoice?f.tool_choice={type:"any"}:"object"==typeof a.toolChoice&&(f.tool_choice={type:"tool",name:a.toolChoice.name}));let g=await this.client.messages.create(f),h="",i=[];for(let a of g.content)if("text"===a.type)h+=a.text;else"tool_use"===a.type&&i.push({id:a.id,name:a.name,arguments:a.input});let j="tool_use"===g.stop_reason?"tool_use":"max_tokens"===g.stop_reason?"length":"stop";return{content:h,toolCalls:i,finishReason:j,usage:{promptTokens:g.usage.input_tokens,completionTokens:g.usage.output_tokens,totalTokens:g.usage.input_tokens+g.usage.output_tokens},model:c,provider:"anthropic",latencyMs:Date.now()-b}}catch(a){throw o.error({err:a,model:c},"Anthropic API call failed"),new k("anthropic",a instanceof Error?a.message:"Unknown error")}}async generateEmbedding(a){throw new k("anthropic","Anthropic does not support embeddings. Use OpenAI embedding provider instead.")}async generateEmbeddings(a){throw new k("anthropic","Anthropic does not support embeddings. Use OpenAI embedding provider instead.")}convertMessages(a){let b=[];for(let c of a)if("system"!==c.role)if("assistant"===c.role){let a=[];if(c.content&&a.push({type:"text",text:c.content}),c.toolCalls)for(let b of c.toolCalls)a.push({type:"tool_use",id:b.id,name:b.name,input:b.arguments});b.push({role:"assistant",content:a})}else"tool"===c.role?b.push({role:"user",content:[{type:"tool_result",tool_use_id:c.toolCallId,content:c.content}]}):b.push({role:"user",content:c.content});return b}}var q=c(8431);let r=n({module:"openai-provider"});class s extends g{constructor(a){super(a),this.providerType="openai",this.client=new q.Ay({apiKey:a.apiKey,...a.baseUrl?{baseURL:a.baseUrl}:{}})}async complete(a){let b=Date.now(),c=a.model??this.config.model;try{let d=this.convertMessages(a.messages,a.systemPrompt),e=a.tools?a.tools.map(a=>({type:"function",function:{name:a.name,description:a.description,parameters:{type:"object",properties:a.parameters.properties,required:a.parameters.required}}})):void 0,f=a.maxTokens??4096,g=this.requiresMaxCompletionTokens(c),i=this.shouldSendTemperature(c,a.temperature),j={model:c,messages:d,...a.jsonMode&&(!e||0===e.length)?{response_format:{type:"json_object"}}:{},...e&&e.length>0?{tools:e}:{},...i?{temperature:a.temperature}:{},...a.stopSequences?{stop:a.stopSequences}:{}};g?j.max_completion_tokens=f:j.max_tokens=f,a.toolChoice&&e&&e.length>0&&("auto"===a.toolChoice?j.tool_choice="auto":"none"===a.toolChoice?j.tool_choice="none":"required"===a.toolChoice?j.tool_choice="required":"object"==typeof a.toolChoice&&(j.tool_choice={type:"function",function:{name:a.toolChoice.name}}));let k=await this.client.chat.completions.create(j),l=k.choices[0],m=l.message,n=(m.tool_calls??[]).map(h),o="tool_calls"===l.finish_reason?"tool_use":"length"===l.finish_reason?"length":"content_filter"===l.finish_reason?"content_filter":"stop";return{content:m.content??"",toolCalls:n,finishReason:o,usage:{promptTokens:k.usage?.prompt_tokens??0,completionTokens:k.usage?.completion_tokens??0,totalTokens:k.usage?.total_tokens??0},model:c,provider:"openai",latencyMs:Date.now()-b}}catch(a){throw r.error({err:a,model:c},"OpenAI API call failed"),new k("openai",a instanceof Error?a.message:"Unknown error")}}requiresMaxCompletionTokens(a){return/^(gpt-5|o1|o3|o4)/i.test(a)}shouldSendTemperature(a,b){return void 0!==b&&(!/^gpt-5/i.test(a)||1===b)}async generateEmbedding(a){try{return(await this.client.embeddings.create({model:this.config.model,input:a})).data[0].embedding}catch(a){throw r.error({err:a},"OpenAI embedding generation failed"),new k("openai",a instanceof Error?a.message:"Embedding generation failed")}}async generateEmbeddings(a){try{return(await this.client.embeddings.create({model:this.config.model,input:a})).data.map(a=>a.embedding)}catch(a){throw r.error({err:a},"OpenAI batch embedding generation failed"),new k("openai",a instanceof Error?a.message:"Batch embedding generation failed")}}convertMessages(a,b){let c=[];for(let d of(b&&c.push({role:"system",content:b}),a))if("system"===d.role)c.push({role:"system",content:d.content});else if("assistant"===d.role){let a=d.toolCalls?.map(a=>({id:a.id,type:"function",function:{name:a.name,arguments:JSON.stringify(a.arguments)}}));c.push({role:"assistant",content:d.content||null,...a&&a.length>0?{tool_calls:a}:{}})}else"tool"===d.role?c.push({role:"tool",content:d.content,tool_call_id:d.toolCallId}):c.push({role:"user",content:d.content});return c}}let t={anthropic:a=>new p(a),openai:a=>new s(a)},u=new Map,v=n({module:"llm-client"});class w{constructor(a,b){this.provider=function(a,b){let c=u.get(a)??t[a];if(!c)throw new j(`Unknown LLM provider: ${a}`);return c(b)}(a,b),v.info({provider:a,model:b.model},"LLM client initialized")}get providerType(){return this.provider.providerType}async complete(a){let b=await this.provider.complete(a);return v.debug({provider:this.provider.providerType,model:b.model,latencyMs:b.latencyMs,tokens:b.usage.totalTokens,toolCalls:b.toolCalls.length},"LLM call completed"),b}async generateEmbedding(a){return this.provider.generateEmbedding(a)}async generateEmbeddings(a){return this.provider.generateEmbeddings(a)}}let x=n({module:"resume-generator"});class y{constructor(a){let b=process.env.OPENAI_API_KEY?.trim(),c=process.env.ANTHROPIC_API_KEY?.trim(),d=b?"openai":"anthropic",e="openai"===d?process.env.OPENAI_MODEL??"gpt-4o-mini":process.env.ANTHROPIC_MODEL??"claude-haiku-4-5";this.llmClient=a??new w(d,{apiKey:b??c??"",model:e,..."openai"===d&&process.env.OPENAI_BASE_URL?{baseUrl:process.env.OPENAI_BASE_URL}:{}})}async generateResume(a,b){let c;x.info({role:a.role,background:b.name},"Generating resume...");let d=this.buildPrompt(a,b);for(let e=1;e<=2;e++)try{let c=await this.llmClient.complete({messages:[{role:"user",content:1===e?d:`${d}

IMPORTANT: Return a single valid JSON object only. No markdown, no explanations.`}],jsonMode:!0,...1===e?{temperature:.8}:{},maxTokens:2e3}),f=this.parseResumeFromText(c.content);return f.generationSource="llm",x.info({role:a.role,background:b.name,name:f.name,attempt:e},"Resume generated successfully"),f}catch(f){c=f;let d=f instanceof Error?f.message:String(f);x.warn({err:d,role:a.role,background:b.name,attempt:e},"Resume generation attempt failed")}let e=c instanceof Error?c.message:String(c);return x.error({reason:e,role:a.role,background:b.name},"Falling back to deterministic resume"),this.buildFallbackResume(a,b)}async generateAllResumes(a,b){let c=new Map;for(let d of a){let a=b[d.slug]||[],e=[];for(let b of a){let a=await this.generateResume(d,b);e.push(a),await new Promise(a=>setTimeout(a,500))}c.set(d.slug,e)}return c}buildPrompt(a,b){return`You are an AI that generates realistic resumes for virtual AI employees. Generate a resume for the following role and background:

**Role:** ${a.role}
**Category:** ${a.category}
**Background:** ${b.name}
**Industry:** ${b.industry}
**Description:** ${b.description}
**Personality Traits:** ${b.personalityTraits.join(", ")}
**Working Style:** ${b.workingStyle}

Generate a realistic resume in JSON format with the following structure:

{
  "name": "FirstName LastName",
  "role": "${a.role}",
  "background": "${b.name}",
  "experience": [
    {
      "company": "Company Name (real company in ${b.industry} industry)",
      "position": "Job Title",
      "duration": "Year-Year (2-4 years each)",
      "achievements": [
        "Specific achievement with metrics (e.g., 'Increased X by Y%')",
        "Another achievement with concrete results",
        "One more achievement showing impact"
      ]
    },
    // 2-3 positions total, showing 6-10 years experience
  ],
  "skills": ["skill1", "skill2", "skill3", ...], // 5-8 relevant skills
  "workingStyle": "One sentence describing how they work (based on background)",
  "personality": ["trait1", "trait2", "trait3"] // From personality traits
}

**Requirements:**
- Use a realistic, diverse name (various ethnicities, genders)
- Use REAL companies from the ${b.industry} industry
- Include 2-3 previous positions showing career progression
- Total experience: 6-10 years
- Achievements must have SPECIFIC metrics and numbers
- Skills should match the role's expertise: ${a.requiredExpertise.join(", ")}
- Working style should reflect: ${b.workingStyle}

**Example (for SEO Engineer with Consumer Tech background):**

{
  "name": "Jordan Kim",
  "role": "SEO Engineer",
  "background": "Consumer Tech Innovator",
  "experience": [
    {
      "company": "Notion",
      "position": "Senior SEO Manager",
      "duration": "2021-2024",
      "achievements": [
        "Grew organic traffic from 2M to 8M monthly visitors (300% increase)",
        "Implemented technical SEO framework that improved site speed by 40%",
        "Led content strategy resulting in 500+ high-authority backlinks"
      ]
    },
    {
      "company": "Airbnb",
      "position": "SEO Specialist",
      "duration": "2018-2021",
      "achievements": [
        "Optimized 50,000+ listing pages for local search, increasing bookings 25%",
        "Built automated keyword research system processing 100K queries monthly",
        "Improved Core Web Vitals scores across 15 international markets"
      ]
    },
    {
      "company": "Dropbox",
      "position": "Digital Marketing Analyst",
      "duration": "2016-2018",
      "achievements": [
        "Conducted A/B tests on landing pages, improving conversion rate 35%",
        "Analyzed user search behavior leading to 3 major product insights",
        "Collaborated with product team on SEO-friendly feature launches"
      ]
    }
  ],
  "skills": ["Technical SEO", "Google Analytics", "A/B Testing", "Python", "Data Analysis", "Content Strategy", "User Research"],
  "workingStyle": "Fast iteration and experimentation. Loves trying new tactics and measuring everything.",
  "personality": ["creative", "experimental", "user-obsessed"]
}

Now generate the resume for ${a.role} with ${b.name} background. Return ONLY the JSON, no additional text.`}parseResumeFromText(a){let b=a.match(/\{[\s\S]*\}/);if(!b)throw Error("Could not extract JSON from LLM response");try{let a=JSON.parse(b[0]);if(!a.name||!a.role||!a.background||!a.experience||!a.skills||!a.workingStyle||!a.personality)throw Error("Resume missing required fields");if(a.experience.length<2)throw Error("Resume must have at least 2 previous positions");return a}catch(d){let b=a.slice(0,400),c=d instanceof Error?d.message:String(d);throw x.warn({err:c,preview:b},"Failed to parse resume JSON"),Error(`Failed to parse resume: ${d}`)}}buildFallbackResume(a,b){let c=this.buildFallbackName(b),d=a.requiredExpertise.slice(0,6);return{name:c,role:a.role,background:b.name,generationSource:"fallback",experience:[{company:`${b.industry} Systems`,position:`Senior ${a.role}`,duration:"2021-2024",achievements:["Led cross-functional initiatives with measurable business impact","Improved team throughput and delivery consistency","Built repeatable processes adopted across multiple projects"]},{company:`${b.industry} Labs`,position:a.role,duration:"2018-2021",achievements:["Delivered production-ready work under tight deadlines","Collaborated with engineering and operations on implementation","Created documentation and playbooks to improve onboarding"]}],skills:d.length>0?d:["communication","execution"],workingStyle:b.workingStyle,personality:b.personalityTraits.slice(0,3)}}buildFallbackName(a){let b=["Jordan","Taylor","Avery","Morgan","Riley"],c=["Reed","Patel","Nguyen","Kim","Rivera"],d=(a.name+a.slug).length,e=b[d%b.length],f=c[3*d%c.length];return`${e} ${f}`}}var z=c(86695);function A(){return e||(e=new z.PrismaClient({log:[{emit:"stdout",level:"error"}]})),e}var B=c(12180),C=c.n(B);let D=n({module:"docker-client"}),E=null;function F(){return E||(E=new(C())({})),E}async function G(){try{let a=F();return await a.ping(),D.info("Docker daemon is available"),!0}catch(a){return D.error({err:a},"Docker daemon is not available"),!1}}async function H(a){try{let b=F();if((await b.listImages({filters:{reference:[a]}})).length>0)return D.info({imageName:a},"Docker image found"),!0;return D.warn({imageName:a},"Docker image not found"),!1}catch(b){return D.error({err:b,imageName:a},"Failed to check if image exists"),!1}}var I=c(79748),J=c(33873);let K=n({module:"workspace-manager"});class L{constructor(a){this.baseWorkspacePath=a??J.join(process.cwd(),"agent-workspaces")}getWorkspacePath(a,b){return J.join(this.baseWorkspacePath,`${a}-${b}`)}async createWorkspace(a,b){let c=this.getWorkspacePath(a,b);try{await I.mkdir(c,{recursive:!0});let d=J.join(c,"projects"),e=J.join(c,"screenshots"),f=J.join(c,"logs"),g=J.join(c,"ports.json");await Promise.all([I.mkdir(d,{recursive:!0}),I.mkdir(e,{recursive:!0}),I.mkdir(f,{recursive:!0})]),await I.writeFile(g,JSON.stringify({allocated:[]},null,2));let h=J.join(c,".bashrc");return await I.writeFile(h,`# Agent workspace bashrc
export PS1="\\u@agent:\\w$ "
alias ll='ls -alh'
alias ..='cd ..'
`),K.info({agentName:a,agentId:b,workspacePath:c},"Workspace created"),{projects:d,screenshots:e,logs:f,ports:g}}catch(c){throw K.error({err:c,agentName:a,agentId:b},"Failed to create workspace"),Error(`Failed to create workspace for ${a}: ${c}`)}}async deleteWorkspace(a,b){let c=this.getWorkspacePath(a,b);try{await I.rm(c,{recursive:!0,force:!0}),K.info({agentName:a,agentId:b,workspacePath:c},"Workspace deleted")}catch(c){throw K.error({err:c,agentName:a,agentId:b},"Failed to delete workspace"),Error(`Failed to delete workspace for ${a}: ${c}`)}}async workspaceExists(a,b){let c=this.getWorkspacePath(a,b);try{return await I.access(c),!0}catch{return!1}}async getWorkspaceSize(a,b){let c=this.getWorkspacePath(a,b),d=async a=>{let b=0;try{for(let c of(await I.readdir(a,{withFileTypes:!0}))){let e=J.join(a,c.name);if(c.isDirectory())b+=await d(e);else{let a=await I.stat(e);b+=a.size}}}catch(b){K.warn({err:b,dirPath:a},"Failed to get directory size")}return b};return d(c)}}let M={"frontend-engineer":{start:3e3,end:3099},"backend-engineer":{start:4e3,end:4099},"api-engineer":{start:5e3,end:5099},"data-engineer":{start:8e3,end:8099},"devops-engineer":{start:9e3,end:9099},"ux-designer":{start:6e3,end:6099}},N={start:7e3,end:7099},O=["frontend-engineer","backend-engineer","api-engineer","data-engineer","devops-engineer","ux-designer"],P=n({module:"container-provisioner"});class Q{constructor(a){this.containers=new Map,this.docker=F(),this.workspaceManager=new L(a)}needsContainer(a){let b=a.toLowerCase().replace(/\s+/g,"-");return O.includes(b)}async provisionForAgent(a){let{agentId:b,agentName:c,role:d,image:e,cpuLimit:f,memoryLimit:g}=a;if(!this.needsContainer(d))return P.info({agentId:b,agentName:c,role:d},"Agent does not need a container"),null;if(!await G())throw Error("Docker daemon is not available. Cannot provision container.");try{let a=e??(d.toLowerCase().replace(/\s+/g,"-").includes("data")?"agent-runtime-python:latest":"agent-runtime-node:latest"),h=M[d.toLowerCase().replace(/\s+/g,"-")]??N;if(!await H(a))throw Error(`Docker image ${a} not found. Please build it first using: docker build -f docker/agent-runtime-node.Dockerfile -t ${a} .`);P.info({agentId:b,agentName:c},"Creating workspace..."),await this.workspaceManager.createWorkspace(c,b);let i=this.workspaceManager.getWorkspacePath(c,b),j=`agent-${b}`;P.info({agentId:b,containerName:j,imageName:a},"Creating container...");let k=await this.docker.createContainer({name:j,Image:a,Hostname:j,Env:[`AGENT_ID=${b}`,`AGENT_ROLE=${d}`,`AGENT_NAME=${c}`],HostConfig:{Binds:[`${i}:/workspace`],PortBindings:this.createPortBindings(h),RestartPolicy:{Name:"unless-stopped"},Memory:this.parseMemoryLimit(g??"4g"),NanoCpus:(f??2)*1e9},ExposedPorts:this.createExposedPorts(h)});P.info({containerName:j},"Starting container..."),await k.start();let l={containerName:j,containerId:k.id,workspacePath:i,portRange:h,imageUsed:a,status:"running"};return this.containers.set(b,l),P.info({agentId:b,containerName:j,containerId:k.id},"Container provisioned successfully"),l}catch(a){throw P.error({err:a,agentId:b,agentName:c,role:d},"Failed to provision container"),Error(`Failed to provision container for ${c}: ${a}`)}}async deprovisionContainer(a){let b=this.containers.get(a);if(!b)return void P.warn({agentId:a},"No container found for agent");try{let c=this.docker.getContainer(b.containerId);P.info({agentId:a,containerName:b.containerName},"Stopping container..."),await c.stop({t:10}),P.info({agentId:a,containerName:b.containerName},"Removing container..."),await c.remove(),this.containers.delete(a),P.info({agentId:a},"Container deprovisioned successfully")}catch(b){throw P.error({err:b,agentId:a},"Failed to deprovision container"),Error(`Failed to deprovision container: ${b}`)}}async getContainerHealth(a){let b=this.containers.get(a);if(!b)return null;try{let a=this.docker.getContainer(b.containerId),c=await a.inspect(),d=await a.stats({stream:!1});return{running:c.State.Running,uptime:c.State.StartedAt,cpuUsage:this.calculateCpuPercent(d),memoryUsage:d.memory_stats?.usage??0,memoryLimit:d.memory_stats?.limit??0,restartCount:c.RestartCount}}catch(b){return P.error({err:b,agentId:a},"Failed to get container health"),null}}getContainerInfo(a){return this.containers.get(a)??null}getAllContainers(){return Array.from(this.containers.values())}async cleanupWorkspace(a,b){await this.workspaceManager.deleteWorkspace(a,b)}createPortBindings(a){let b={};for(let c=a.start;c<=a.end;c++)b[`${c}/tcp`]=[{HostPort:`${c}`}];return b}createExposedPorts(a){let b={};for(let c=a.start;c<=a.end;c++)b[`${c}/tcp`]={};return b}parseMemoryLimit(a){let b=a.match(/^(\d+)([kmg]?)$/i);if(!b)return 0x100000000;let c=parseInt(b[1],10);switch(b[2].toLowerCase()){case"k":return 1024*c;case"m":return 1024*c*1024;case"g":return 1024*c*1048576;default:return c}}calculateCpuPercent(a){let b=a.cpu_stats.cpu_usage.total_usage-a.precpu_stats.cpu_usage.total_usage,c=a.cpu_stats.system_cpu_usage-a.precpu_stats.system_cpu_usage,d=a.cpu_stats.online_cpus||1;return c>0&&b>0?b/c*d*100:0}}let R=n({module:"dynamic-agent-loader"});class S{constructor(a){this.containerProvisioner=a??new Q}async loadAllHiredAgents(){let a=A();R.info("Loading hired agents from database...");let b=await a.hiredAgent.findMany({where:{status:"active"},include:{agent:!0,template:!0,background:!0}});R.info({count:b.length},"Found hired agents");let c=[];for(let a of b)try{let b=await this.loadAgent(a.agentId);b&&c.push(b)}catch(b){R.error({err:b,agentId:a.agentId},"Failed to load agent")}return R.info({count:c.length},"Successfully loaded agents"),c}async loadAgent(a){let b=A(),c=await b.hiredAgent.findUnique({where:{agentId:a},include:{agent:!0,template:!0,background:!0}});if(!c)return R.warn({agentId:a},"No hired agent found"),null;R.info({agentId:a,role:c.template.role,background:c.background.name},"Loading agent...");let d=this.buildSystemPrompt(c.template.baseSystemPrompt,c.background.promptModifiers);c.agent.systemPrompt!==d&&await b.agent.update({where:{id:a},data:{systemPrompt:d}});let e=c.agent.containerInfo;if(c.template.needsContainer&&!e){R.info({agentId:a},"Provisioning container for agent...");let d=await this.containerProvisioner.provisionForAgent({agentId:c.agent.id,agentName:c.agent.name,role:c.template.role});d&&(e=d,await b.agent.update({where:{id:a},data:{containerInfo:d}}),R.info({agentId:a,containerName:d.containerName},"Container provisioned"))}else c.template.needsContainer&&e&&R.info({agentId:a},"Agent already has container provisioned");return{agent:c.agent,template:{role:c.template.role,slug:c.template.slug,needsContainer:c.template.needsContainer,defaultTools:c.template.defaultTools},background:{name:c.background.name,promptModifiers:c.background.promptModifiers},resume:c.generatedResume,containerInfo:e}}async hireAgent(a){let b=A(),c=process.env.OPENAI_API_KEY?.trim()?{provider:"openai",model:process.env.OPENAI_MODEL??"gpt-4o-mini"}:{provider:"anthropic",model:process.env.ANTHROPIC_MODEL??"claude-haiku-4-5"};R.info({templateId:a.templateId,backgroundId:a.backgroundId,name:a.generatedName},"Hiring new agent...");let d=await b.roleTemplate.findUnique({where:{id:a.templateId}});d||(d=await b.roleTemplate.findUnique({where:{slug:a.templateId}}));let e=await b.background.findUnique({where:{id:a.backgroundId}});if(!d||!e)throw Error("Template or background not found");if(e.templateId!==d.id)throw Error("Background does not belong to template");let f=this.buildSystemPrompt(d.baseSystemPrompt,e.promptModifiers),g=a.generatedName.toLowerCase().replace(/\s+/g,"-"),h=this.selectToolsForAgent(d,e),i=await b.agent.create({data:{name:g,displayName:a.generatedName,systemPrompt:f,llmProvider:c.provider,llmModel:c.model,llmTemperature:.7,llmMaxTokens:8192,tools:h,slackChannels:a.slackChannels??[],memoryNamespace:g,role:d.role,team:d.team,reportsTo:d.reportsTo,expertise:[...d.requiredExpertise,...e.expertiseBoost],enabled:!0}});await b.hiredAgent.create({data:{agentId:i.id,templateId:d.id,backgroundId:e.id,hiredBy:a.hiredBy,generatedName:a.generatedName,generatedResume:a.generatedResume,customizations:a.customizations,status:"active"}}),R.info({agentId:i.id,agentName:i.name,role:d.role},"Agent hired successfully");let j=await this.loadAgent(i.id);if(!j)throw Error("Failed to load newly hired agent");return j}async terminateAgent(a){let b=A();R.info({agentId:a},"Terminating agent...");let c=await b.agent.findUnique({where:{id:a}});if(!c)throw Error("Agent not found");if(c.containerInfo)try{await this.containerProvisioner.deprovisionContainer(a),R.info({agentId:a},"Container stopped")}catch(b){R.error({err:b,agentId:a},"Failed to stop container")}await b.agent.update({where:{id:a},data:{enabled:!1}}),await b.hiredAgent.updateMany({where:{agentId:a},data:{status:"terminated",terminatedAt:new Date}}),R.info({agentId:a},"Agent terminated")}buildSystemPrompt(a,b){return`${a}

--- BACKGROUND ---
${b}`}selectToolsForAgent(a,b){let c=[...a.defaultTools];return a.needsContainer&&["persistent_bash","file_tree","port_allocate","process_manage","file_read","file_write"].forEach(a=>{c.includes(a)||c.push(a)}),(b.expertiseBoost.includes("ux")||b.expertiseBoost.includes("frontend"))&&!c.includes("browser_screenshot")&&c.push("browser_screenshot"),c}}let T=null,U=null;function V(){if(!T){let a=function(a){if("openai"!==a.provider)return a;let b=process.env.OPENAI_RESUME_MODEL?.trim(),c=b&&b.length>0?b:a.model.startsWith("gpt-5")?"gpt-4o-mini":a.model;return{...a,model:c}}(function(){let a=process.env.OPENAI_API_KEY?.trim();if(a)return{provider:"openai",apiKey:a,model:process.env.OPENAI_MODEL??"gpt-4o-mini",baseUrl:process.env.OPENAI_BASE_URL};let b=process.env.ANTHROPIC_API_KEY?.trim();if(b)return{provider:"anthropic",apiKey:b,model:process.env.ANTHROPIC_MODEL??"claude-haiku-4-5",baseUrl:process.env.ANTHROPIC_BASE_URL};throw Error("No LLM API key configured. Set ANTHROPIC_API_KEY or OPENAI_API_KEY.")}());T=new y(new w(a.provider,{apiKey:a.apiKey,model:a.model,baseUrl:a.baseUrl}))}return T}function W(){return U||(U=new S(new Q)),U}function X(){return A()}},78335:()=>{},96487:()=>{}};